# ML Service Configuration

mqtt:
  broker: "mosquitto"  # hostname in docker network
  port: 1883
  client_id: "ml-service"
  topics:
    inference_request: "ml/inference/request/#"
    window_control: "window/{device_id}/control"
  qos: 1
  keepalive: 60
  reconnect_delay: 5  # seconds

model:
  path: "/app/models/window_regressor.pth"
  version: "v1.0.0"
  input_features: 3  # temperature, humidity, sound_volume
  output_range:
    min: 0.0
    max: 100.0

inference:
  # Normalization will use 0.1 and 0.9 percentiles computed from training data
  # These are stored in the model metadata
  percentile_low: 0.1
  percentile_high: 0.9

  # Confidence thresholds
  min_confidence: 0.0  # Minimum confidence to publish (0 = always publish)

logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "json"  # json or text
